{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32769, 15626)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import cross_validation\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import numpy as np\n",
    "from sklearn import svm, grid_search \n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "%matplotlib inline\n",
    "\n",
    "full_data = pd.read_csv(\"train.csv\")\n",
    "data = full_data.drop(full_data.columns[[2,3,4,7,9]], axis=1)\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "t = data.values[:,:1]\n",
    "data = full_data.drop(full_data.columns[[0]],axis=1)\n",
    "encoder.fit(data)\n",
    "data = encoder.transform(data)\n",
    "x = data\n",
    "#x = data.values[:,0:]\n",
    "print data.shape\n",
    "y = []\n",
    "\n",
    "for a in range(0,len(t)):\n",
    "    y.append(int(t[a][0]))\n",
    "#x = enc.fit_transform(x)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "#clf1 = linear_model.LogisticRegression(n_jobs=-1)\n",
    "#clf = linear_model.ElasticNet()\n",
    "#clf = naive_bayes.GaussianNB()\n",
    "clf1 = RandomForestClassifier(n_estimators=200,warm_start = True)\n",
    "#clf1 = GradientBoostingClassifier()\n",
    "clf1 = clf1.fit(x, y)\n",
    "#print clf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#currently getting .77\n",
    "clf2 = tree.DecisionTreeClassifier(splitter = 'best',class_weight = 'balanced')\n",
    "clf2 = clf2.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf3 = svm.SVC(class_weight = 'balanced',cache_size =2000,C=950,tol = .001,probability=True)\n",
    "#clf3 = clf3.fit(x_train, y_train)0.82032\n",
    "#clf3 = LogisticRegression()\n",
    "#clf3 = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1000, fit_intercept=True, intercept_scaling=100, \n",
    "                          #class_weight='balanced', random_state=None, solver='newton-cg', max_iter=1000, multi_class='ovr', \n",
    "                          #verbose=0, warm_start=False, n_jobs=1)\n",
    "clf3 = clf3.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58921, 15626)\n"
     ]
    }
   ],
   "source": [
    "full_data = pd.read_csv(\"test.csv\")\n",
    "data = full_data.drop(full_data.columns[[2,3,4,7,9]], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "t = data.values[:,:1]\n",
    "data = full_data.drop(full_data.columns[[0]],axis=1)\n",
    "data = encoder.transform(data)\n",
    "#x = data.values[:,0:]\n",
    "print data.shape\n",
    "x=data\n",
    "y=[]\n",
    "\n",
    "for a in range(0,len(t)):\n",
    "    y.append(int(t[a][0]))\n",
    "#x = enc.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "derp\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "pred1 = clf1.predict(x)\n",
    "pred2 = clf2.predict(x)\n",
    "pred3 = clf3.predict_proba(x)[:, 1]\n",
    "#scores.predict(x)\n",
    "pred = []\n",
    "for i in range (0,len(pred1)):\n",
    "    if(pred1[i]+pred2[i]>=2):\n",
    "        pred.append(1)\n",
    "    else:\n",
    "        pred.append(0)\n",
    "        \n",
    "temp = []\n",
    "\n",
    "for i in range (0, len(pred1)):\n",
    "    a = []\n",
    "    a.append(y[i])\n",
    "    a.append(pred3[i])\n",
    "    temp.append(a)\n",
    "my_df = pd.DataFrame(temp)\n",
    "my_df.to_csv('testout.csv',index=False,header=['Id','Action'])\n",
    "print 'derp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "AUC (fold 1/10): 0.864596\n",
      "AUC (fold 2/10): 0.872631\n",
      "AUC (fold 3/10): 0.877054\n",
      "AUC (fold 4/10): 0.879776\n",
      "AUC (fold 5/10): 0.849488\n",
      "AUC (fold 6/10): 0.876836\n",
      "AUC (fold 7/10): 0.852830\n",
      "AUC (fold 8/10): 0.859904\n",
      "AUC (fold 9/10): 0.861284\n",
      "AUC (fold 10/10): 0.871692\n",
      "Mean AUC: 0.866609\n",
      "Enter name for submission file: testout\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Amazon Access Challenge Starter Code\n",
    "\n",
    "These files provide some starter code using \n",
    "the scikit-learn library. It provides some examples on how\n",
    "to design a simple algorithm, including pre-processing,\n",
    "training a logistic regression classifier on the data,\n",
    "assess its performance through cross-validation and some \n",
    "pointers on where to go next.\n",
    "\n",
    "Paul Duan <email@paulduan.com>\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import (metrics, cross_validation, linear_model, preprocessing)\n",
    "\n",
    "SEED = 42  # always use a seed for randomized procedures\n",
    "\n",
    "\n",
    "def load_data(filename, use_labels=True):\n",
    "    \"\"\"\n",
    "    Load data from CSV files and return them as numpy arrays\n",
    "    The use_labels parameter indicates whether one should\n",
    "    read the first column (containing class labels). If false,\n",
    "    return all 0s. \n",
    "    \"\"\"\n",
    "\n",
    "    # load column 1 to 8 (ignore last one)\n",
    "    data = np.loadtxt(open(filename), delimiter=',',\n",
    "                      usecols=range(1, 9), skiprows=1)\n",
    "    if use_labels:\n",
    "        labels = np.loadtxt(open(filename), delimiter=',',\n",
    "                            usecols=[0], skiprows=1)\n",
    "    else:\n",
    "        labels = np.zeros(data.shape[0])\n",
    "    return labels, data\n",
    "\n",
    "\n",
    "def save_results(predictions, filename):\n",
    "    \"\"\"Given a vector of predictions, save results in CSV format.\"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"id,ACTION\\n\")\n",
    "        for i, pred in enumerate(predictions):\n",
    "            f.write(\"%d,%f\\n\" % (i + 1, pred))\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Fit models and make predictions.\n",
    "    We'll use one-hot encoding to transform our categorical features\n",
    "    into binary features.\n",
    "    y and X will be numpy array objects.\n",
    "    \"\"\"\n",
    "    model = linear_model.LogisticRegression(C=3)  # the classifier we'll use\n",
    "    model = AdaBoostClassifier(base_estimator=model)\n",
    "\n",
    "    # === load data in memory === #\n",
    "    print \"loading data\"\n",
    "    y, X = load_data('train.csv')\n",
    "    y_test, X_test = load_data('test.csv', use_labels=False)\n",
    "\n",
    "    # === one-hot encoding === #\n",
    "    # we want to encode the category IDs encountered both in\n",
    "    # the training and the test set, so we fit the encoder on both\n",
    "    encoder = preprocessing.OneHotEncoder()\n",
    "    encoder.fit(np.vstack((X, X_test)))\n",
    "    X = encoder.transform(X)  # Returns a sparse matrix (see numpy.sparse)\n",
    "    X_test = encoder.transform(X_test)\n",
    "\n",
    "    # if you want to create new features, you'll need to compute them\n",
    "    # before the encoding, and append them to your dataset after\n",
    "\n",
    "    # === training & metrics === #\n",
    "    mean_auc = 0.0\n",
    "    n = 10  # repeat the CV procedure 10 times to get more precise results\n",
    "    for i in range(n):\n",
    "        # for each iteration, randomly hold out 20% of the data as CV set\n",
    "        X_train, X_cv, y_train, y_cv = cross_validation.train_test_split(\n",
    "            X, y, test_size=.20, random_state=i*SEED)\n",
    "\n",
    "        # if you want to perform feature selection / hyperparameter\n",
    "        # optimization, this is where you want to do it\n",
    "\n",
    "        # train model and make predictions\n",
    "        model.fit(X_train, y_train) \n",
    "        preds = model.predict_proba(X_cv)[:, 1]\n",
    "\n",
    "        # compute AUC metric for this CV fold\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_cv, preds)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "        print \"AUC (fold %d/%d): %f\" % (i + 1, n, roc_auc)\n",
    "        mean_auc += roc_auc\n",
    "\n",
    "    print \"Mean AUC: %f\" % (mean_auc/n)\n",
    "\n",
    "    # === Predictions === #\n",
    "    # When making predictions, retrain the model on the whole training set\n",
    "    model.fit(X, y)\n",
    "    preds = model.predict_proba(X_test)[:, 1]\n",
    "    filename = raw_input(\"Enter name for submission file: \")\n",
    "    save_results(preds, filename + \".csv\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
